# -*- coding: utf-8 -*-
"""Mosaic PS1 Submission

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ClXCqnCxOpL0F_wMlvd3ZhvmmDEplCs
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv
import os
import tensorflow as tf
import keras
from keras.models import model_from_json

# Characters = 'क ख ग घ ङ च छ ज झ ञ ट ठ ड ढ ण त थ द ध न प फ ब भ म य र ल व श ष स ह क्ष त्र ज्ञ ० १ २ ३ ४ ५ ६ ७ ८ ९'
hindi_labels = ['ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'क', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'ख', 'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९']

from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model(weights).h5")
print("Loaded model from disk")

def convert_toHindi(l):
    s=''
    for c in l:
        s = s+c
    return s

def crop_rect(img, rect):
    # get the parameter of the small rectangle
    center = rect[0]
    size = rect[1]
    angle = rect[2]
    change = False
    if(abs(angle)>40):
      angle = 90+angle
      change=True
    center, size = tuple(map(int, center)), tuple(map(int, size))

    # get row and col num in img
    height, width = img.shape[0], img.shape[1]
    # print("width: {}, height: {}".format(width, height))
    # print(f"angle = ",angle)
    M = cv.getRotationMatrix2D(center, angle, 1)
    # print(M)
    img_rot = cv.warpAffine(img, M, (width, height))
    # img_rot = img_rot.transpose((1, 0, 2))
    # print(img_rot)
    # plt.imshow(img_rot)
    # size = [size[1],size[0]]
    if(change):
      size = size[::-1]
    
    img_crop = cv.getRectSubPix(img_rot, size, center)
    # print(f"size of cropped = ",img_crop.shape)
    # # img_crop = np.reshape(img_crop,(43,273,-1))
    # # img_crop = img_crop.transpose((1, 0, 2))
    # print(f"size of cropped = ",img_crop.shape)
    # print(f"size of rot = ",img_rot.shape)
    return img_crop, img_rot

def word_segment_krega_image_m_se(img):
  #image input
  # img = cv.imread(curr_dir+"data/char13.jpeg")
  img = cv.copyMakeBorder( img, 0, 0, 5, 5,cv.BORDER_CONSTANT,None, (255,255,255))
  # img = cv.imread("big2.jpeg")
  # plt.imshow(img)
  # plt.figure(figsize=(50,50))
  #making a binary image
  kernel = np.ones((3,3), np.uint8)
  imgGray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
  imgBlur = cv.GaussianBlur(imgGray,(7,7),1)
  ret,imgThresh = cv.threshold(imgBlur,10,255,cv.THRESH_BINARY+cv.THRESH_OTSU) #100
  # plt.subplot(131)
  # plt.imshow(imgThresh,cmap='gray')

  imgThresh1 = cv.erode(imgThresh, kernel, iterations=5) 
  imgThresh = cv.erode(imgThresh, kernel, iterations=1)##since some part may not attatch to the upper line so erode used
  imgThresh = cv.dilate(imgThresh, kernel, iterations=1)
  # plt.imshow(imgThresh,cmap='gray')
  imgCanny = cv.Canny(imgThresh1,80,80)
  # plt.imshow(imgCanny)
  img_dilation = cv.dilate(imgCanny, kernel, iterations=2)
  img_erosion = cv.erode(img_dilation, kernel, iterations=2)

  # plt.imshow(img_erosion)
  contours, heirarchy = cv.findContours(img_erosion,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)
  # print(len(contours))

  # imgBlank = np.zeros_like(img)
  maxCnt = contours[0]
  max_area =0
  row,col=img_erosion.shape

  for i,cnt in enumerate(contours):
    x,y,w,h = cv.boundingRect(cnt)
    cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
  #   plt.figure(figsize=(100,100))
  #   plt.subplot(len(contours),1,i+1)
  #   plt.imshow(img)
  #   plt.show()
    area = cv.contourArea(cnt)
    # print(f"area = ",cv.contourArea(cnt))
    if(area>=max_area and (area<row*col*0.98)):
      max_area = cv.contourArea(cnt)
      maxCnt = cnt
    # if cv.contourArea(cnt) < 500:
    #   continue
    # x,y,w,h = cv.boundingRect(cnt)
    # cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
  # print(cv.contourArea(maxCnt))
  rect = cv.minAreaRect(maxCnt)
  cv.drawContours(img,maxCnt,0,(0,255,0),3)
  box = cv.boxPoints(rect)  
  box = np.int0(box)
  # print(box)
  cv.drawContours(img,[box],0,(0,0,255),2)
  # plt.subplot(132)
  # plt.imshow(img)
  img_cropped,_ = crop_rect(imgThresh,rect) #image
  # plt.imshow(img_cropped)
  # cv.imwrite("hello.png",img_cropped)
  # cv.drawContours(img,[box],0,(0,0,255),2)
  # plt.subplot(133)
  # plt.imshow(img_cropped,cmap='gray')
  # plt.imshow(img)
  return img_cropped

def word_ke_uper_ka_danda_removal(img_cropped):
  img_without_danda =0
  new_height = int(img_cropped.shape[0]*(0.09)+13)
  # print(new_height)
  if(img_cropped[0].shape>img_cropped[1].shape):
    img_without_danda = img_cropped[:,new_height:][:]
  else:
    img_without_danda = img_cropped[new_height:,:][:]

  # plt.imshow(img_without_danda,cmap='gray')

  # print(img_without_danda.shape)
  #(105, 614) #(33, 640)

  src = img_without_danda
  top = int(0.2 * src.shape[0])  # shape[0] = rows
  bottom = top
  left = int(0.05 * src.shape[1])  # shape[1] = cols # WE CAN DO ZEZRO HERE 
  left =0
  right = left
  cropped_with_border = cv.copyMakeBorder( img_without_danda, top, bottom, left, right,cv.BORDER_CONSTANT,None, (255,255,255))
  # plt.imshow(cropped_with_border,cmap='gray')
  # print(cropped_with_border.shape)
  return cropped_with_border

def draw_bounding_box_over_characters(cropped_with_border):
  # from google.colab.patches import cv2_imshow
  # imgGray = cv.cvtColor(cropped_with_border,cv.COLOR_BGR2GRAY)
  # imgBlur = cv.GaussianBlur(imgGray,(3,3),1)
  # ret,imgThresh = cv.threshold(imgGray,100,255,cv.THRESH_BINARY+cv.THRESH_OTSU) 
  imgThresh = cropped_with_border#cv.erode(imgThresh, kernel, iterations=2) ##since some part may not attatch to the upper line so erode used
  # imgBlank = np.zeros_like(img)
  imgCanny = cv.Canny(imgThresh,80,80)
  # plt.imshow(imgThresh,cmap='gray')
  # cv2_imshow(imgGray)
  kernel = np.ones((3,3), np.uint8)
  img_dilation = cv.dilate(imgCanny, kernel, iterations=1)
  img_erosion = cv.erode(img_dilation, kernel, iterations=1)
  # plt.imshow(imgCanny)
  contours, heirarchy = cv.findContours(img_erosion,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)
  img_h,img_w = img_erosion.shape
  img_area = img_h*img_w
  # print(np.sqrt(img_area))
  # print(len(contours))
  i =0

  width_def = []


  for cnt in contours:
    # print(f"area = ",cv.contourArea(cnt))
    if cv.contourArea(cnt) < (np.sqrt(img_area)):
      continue
    x,y,w,h = cv.boundingRect(cnt)
    width_def.append([x,x+w])
    # separate_char = cropped_with_border[0:y+h+int(y*0.1),x-int(x*0.05):x+w,:] #check for out of index
    # sexy = int(separate_char.shape[0]*0.08)
    # separate_char[0:sexy][0:][:]=0
    # separate_char[0:10][0:10][:]=0
    # print(separate_char[:2,:2][:])
    # plt.imshow(separate_char)
    i=i+1
    # cv.imwrite("char"+str(i)+".png",separate_char)
    cv.rectangle(cropped_with_border,(x,y),(x+w,y+h),(0,255,0),2)
  # print(i)
  n_char = i
  # plt.imshow(cropped_with_border,cmap = 'gray')
  return width_def, n_char

def contours_ko_order_mai_ye_krega(img_cropped,width_def):
  width_def
  width_def = sorted(width_def)
  # print(width_def)
  # fax = img_cropped[:,width_def[0][0]:width_def[0][1]]
  i=0
  # plt.figure(figsize=(10,10))
  # plt.axis('off')
  array_of_char_images = []
  for i in range(len(width_def)):
    fax = img_cropped[:,width_def[i][0]:width_def[i][1]]
    array_of_char_images.append(fax)
    # plt.subplot(1,len(width_def),i+1)
    # plt.axis('off')
    # plt.imshow(fax,cmap='gray')
    
    cv.imwrite("char_"+str(i)+".png",fax)

def model_ko_upload_to_krlia_predict_ye_krega(n_char):
  ans =[]
  for i in range(n_char):
      path = 'char_'+str(i)+'.png'
      img2 = tf.keras.preprocessing.image.load_img(
          path, color_mode="grayscale", target_size=(64,64), interpolation="nearest") 
      input_arr = keras.preprocessing.image.img_to_array(img2)
      invert = 255 - input_arr
      invert = invert/255.0

      # pred = model.predict(input_arr)
      t= np.expand_dims(invert,axis =0)
      p = loaded_model.predict(t,batch_size=1)
      ind = np.argmax(p)
      ans.append(hindi_labels[ind])
  # print(convert_toHindi(ans)).
  # print(ans)
  return ans

def predict(image):
  img_cropped = word_segment_krega_image_m_se(image)
  image_without_danda = word_ke_uper_ka_danda_removal(img_cropped)
  width_def, n_char = draw_bounding_box_over_characters(image_without_danda)
  contours_ko_order_mai_ye_krega(img_cropped,width_def)
  answer = model_ko_upload_to_krlia_predict_ye_krega(n_char)
  return answer

image = cv.imread("big3.jpeg")
print(predict(image))

# !pip freeze > requirements.txt

