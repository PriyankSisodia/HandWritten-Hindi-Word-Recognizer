# -*- coding: utf-8 -*-
"""Mosaic PS1 _ Version 2.5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1leuo-tCJXEfiKG5rkWiWDKFkqSOcx_rj

#Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install kaggle

#upload the kaggle json file
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

##change the permission
!chmod 600 ~/.kaggle/kaggle.json


#link of datset
##it will be added in zip form
!kaggle datasets download -d jhashanku007/devnagri-hindi-dataset
!unzip devnagri-hindi-dataset.zip

import pandas as pd
import numpy as np
import os

categories = []                         ##saving categories of each file
filenames = os.listdir("/content/DevanagariHandwrittenCharacterDataset/Train")
print("Total Training Images = " + str(len(filenames)))
only_char =[]
for files in filenames:                   ##file name example - cat.10004.jpg
  if(files[0]=='d'):
    continue
  category = files.split("_")[1]          ##getting category by name of file
  categories.append(int(category))
  only_char.append(files)
dataFrame = pd.DataFrame({"FileName":only_char,"Category":categories})
dataFrame.head()

dataFrame = dataFrame.sort_values("Category")

dataFrame                                            #sorted

"""#Croping the word from the image"""

import cv2 as cv
import matplotlib.pyplot as plt
import numpy as np

from google.colab.patches import cv2_imshow

curr_dir = r'/content/drive/MyDrive/Colab Notebooks/Mosaic/PS1/'

def crop_rect(img, rect):
    # get the parameter of the small rectangle
    center = rect[0]
    size = rect[1]
    angle = rect[2]
    change = False
    if(abs(angle)>40):
      angle = 90+angle
      change=True
    center, size = tuple(map(int, center)), tuple(map(int, size))

    # get row and col num in img
    height, width = img.shape[0], img.shape[1]
    print("width: {}, height: {}".format(width, height))
    print(f"angle = ",angle)
    M = cv.getRotationMatrix2D(center, angle, 1)
    print(M)
    img_rot = cv.warpAffine(img, M, (width, height))
    # img_rot = img_rot.transpose((1, 0, 2))
    # print(img_rot)
    # plt.imshow(img_rot)
    # size = [size[1],size[0]]
    if(change):
      size = size[::-1]
    
    img_crop = cv.getRectSubPix(img_rot, size, center)
    print(f"size of cropped = ",img_crop.shape)
    # img_crop = np.reshape(img_crop,(43,273,-1))
    # img_crop = img_crop.transpose((1, 0, 2))
    print(f"size of cropped = ",img_crop.shape)
    print(f"size of rot = ",img_rot.shape)
    return img_crop, img_rot
# imgrot,_ = crop_rect(img,rect)
# plt.imshow(imgrot)

#image input
img = cv.imread(curr_dir+"data/char13.jpeg")
img = cv.copyMakeBorder( img, 0, 0, 5, 5,cv.BORDER_CONSTANT,None, (255,255,255))
# img = cv.imread("big2.jpeg")
# plt.imshow(img)
# plt.figure(figsize=(50,50))
#making a binary image
kernel = np.ones((3,3), np.uint8)
imgGray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
imgBlur = cv.GaussianBlur(imgGray,(7,7),1)
ret,imgThresh = cv.threshold(imgBlur,10,255,cv.THRESH_BINARY+cv.THRESH_OTSU) #100
plt.subplot(131)
plt.imshow(imgThresh,cmap='gray')

imgThresh1 = cv.erode(imgThresh, kernel, iterations=5) 
imgThresh = cv.erode(imgThresh, kernel, iterations=1)##since some part may not attatch to the upper line so erode used
imgThresh = cv.dilate(imgThresh, kernel, iterations=1)
# plt.imshow(imgThresh,cmap='gray')
imgCanny = cv.Canny(imgThresh1,80,80)
plt.imshow(imgCanny)
img_dilation = cv.dilate(imgCanny, kernel, iterations=2)
img_erosion = cv.erode(img_dilation, kernel, iterations=2)

# plt.imshow(img_erosion)
contours, heirarchy = cv.findContours(img_erosion,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)
print(len(contours))

# imgBlank = np.zeros_like(img)
maxCnt = contours[0]
max_area =0
row,col=img_erosion.shape

for i,cnt in enumerate(contours):
  x,y,w,h = cv.boundingRect(cnt)
  cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
#   plt.figure(figsize=(100,100))
#   plt.subplot(len(contours),1,i+1)
#   plt.imshow(img)
#   plt.show()
  area = cv.contourArea(cnt)
  print(f"area = ",cv.contourArea(cnt))
  if(area>=max_area and (area<row*col*0.98)):
    max_area = cv.contourArea(cnt)
    maxCnt = cnt
  # if cv.contourArea(cnt) < 500:
  #   continue
  # x,y,w,h = cv.boundingRect(cnt)
  # cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
print(cv.contourArea(maxCnt))
rect = cv.minAreaRect(maxCnt)
cv.drawContours(img,maxCnt,0,(0,255,0),3)
box = cv.boxPoints(rect)  
box = np.int0(box)
print(box)
cv.drawContours(img,[box],0,(0,0,255),2)
plt.subplot(132)
plt.imshow(img)
img_cropped,_ = crop_rect(imgThresh,rect) #image
# plt.imshow(img_cropped)
cv.imwrite("hello.png",img_cropped)
# cv.drawContours(img,[box],0,(0,0,255),2)
plt.subplot(133)
plt.imshow(img_cropped,cmap='gray')
# plt.imshow(img)

88*159

"""##Function that will crop

#Extracting words from the cropped image

###Image without the danda
"""

img_without_danda =0
new_height = int(img_cropped.shape[0]*(0.09)+13)
print(new_height)
if(img_cropped[0].shape>img_cropped[1].shape):
  img_without_danda = img_cropped[:,new_height:][:]
else:
  img_without_danda = img_cropped[new_height:,:][:]

plt.imshow(img_without_danda,cmap='gray')

print(img_without_danda.shape)
#(105, 614) #(33, 640)

src = img_without_danda
top = int(0.2 * src.shape[0])  # shape[0] = rows
bottom = top
left = int(0.05 * src.shape[1])  # shape[1] = cols # WE CAN DO ZEZRO HERE 
left =0
right = left
cropped_with_border = cv.copyMakeBorder( img_without_danda, top, bottom, left, right,cv.BORDER_CONSTANT,None, (255,255,255))
plt.imshow(cropped_with_border,cmap='gray')
print(cropped_with_border.shape)

# from google.colab.patches import cv2_imshow
# imgGray = cv.cvtColor(cropped_with_border,cv.COLOR_BGR2GRAY)
# imgBlur = cv.GaussianBlur(imgGray,(3,3),1)
# ret,imgThresh = cv.threshold(imgGray,100,255,cv.THRESH_BINARY+cv.THRESH_OTSU) 
imgThresh = cropped_with_border#cv.erode(imgThresh, kernel, iterations=2) ##since some part may not attatch to the upper line so erode used
# imgBlank = np.zeros_like(img)
imgCanny = cv.Canny(imgThresh,80,80)
plt.imshow(imgThresh,cmap='gray')
# cv2_imshow(imgGray)
img_dilation = cv.dilate(imgCanny, kernel, iterations=1)
img_erosion = cv.erode(img_dilation, kernel, iterations=1)
# plt.imshow(imgCanny)
contours, heirarchy = cv.findContours(img_erosion,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)
img_h,img_w = img_erosion.shape
img_area = img_h*img_w
print(np.sqrt(img_area))
print(len(contours))
i =0
###############################################
width_def = []

##############################################
for cnt in contours:
  print(f"area = ",cv.contourArea(cnt))
  if cv.contourArea(cnt) < (np.sqrt(img_area)):
    continue
  x,y,w,h = cv.boundingRect(cnt)
  width_def.append([x,x+w])
  # separate_char = cropped_with_border[0:y+h+int(y*0.1),x-int(x*0.05):x+w,:] #check for out of index
  # sexy = int(separate_char.shape[0]*0.08)
  # separate_char[0:sexy][0:][:]=0
  # separate_char[0:10][0:10][:]=0
  # print(separate_char[:2,:2][:])
  # plt.imshow(separate_char)
  i=i+1
  # cv.imwrite("char"+str(i)+".png",separate_char)
  cv.rectangle(cropped_with_border,(x,y),(x+w,y+h),(0,255,0),2)
print(i)
n_char = i
plt.imshow(cropped_with_border,cmap = 'gray')

width_def
width_def = sorted(width_def)
print(width_def)
# fax = img_cropped[:,width_def[0][0]:width_def[0][1]]
i=0
plt.figure(figsize=(10,10))
plt.axis('off')
for i in range(len(width_def)):
  fax = img_cropped[:,width_def[i][0]:width_def[i][1]]
  plt.subplot(1,len(width_def),i+1)
  plt.axis('off')
  plt.imshow(fax,cmap='gray')
  
  cv.imwrite("big2_"+str(i)+".png",fax)

from keras.models import model_from_json
json_file = open(curr_dir+'model (1).json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights(curr_dir+"model(weights).h5")
print("Loaded model from disk")

loaded_model.summary()



from keras.preprocessing import image 
import numpy as np
from google.colab import files

#uploading
# uploaded = files.upload()
# path = uploaded.keys()
path = '/content/big2_0.png'
#resizing to size fed into cnn
img = image.load_img(path,target_size=(64,64)) 
x = image.img_to_array(img)
x = np.expand_dims(x,axis =0)

#prediction
pred = loaded_model.predict(x,batch_size=1)

x.shape

"""**for Input image testing**"""

import tensorflow as tf
import keras
import cv2 as cv
import matplotlib.pyplot as plt
ans =[]
for i in range(n_char):
    path = 'big2_'+str(i)+'.png'
    img2 = tf.keras.preprocessing.image.load_img(
        path, color_mode="grayscale", target_size=(64,64), interpolation="nearest") 
    input_arr = keras.preprocessing.image.img_to_array(img2)
    invert = 255 - input_arr
    invert = invert/255.0

    # pred = model.predict(input_arr)
    t= np.expand_dims(invert,axis =0)
    p = loaded_model.predict(t,batch_size=1)
    ind = np.argmax(p)
    ans.append(hindi_labels[ind])
print(convert_toHindi(ans))

def convert_toHindi(l):
    s=''
    for c in l:
        s = s+c
    return s

input_arr = input_arr.astype('uint8')

print(input_arr.shape, input_arr)

plt.imshow(input_arr,cmap='gray')

invert = 255 - input_arr

plt.imshow(invert)

invert

"""**for testing from Dataset**"""

# invert= np.expand_dims(invert,axis =0).
trin_path = r'/content/DevanagariHandwrittenCharacterDataset/Train/character_14_dhaa/10716.png'
trained_na = cv.imread(trin_path)
img2 = tf.keras.preprocessing.image.load_img(
      trin_path, grayscale=True, color_mode="grayscale", target_size=(64,64), interpolation="nearest"
) 
input_arr = keras.preprocessing.image.img_to_array(img2)
invert = input_arr/255.0
t= np.expand_dims(invert,axis =0)
p = loaded_model.predict(t,batch_size=1)
ind = np.argmax(p)
print(ind)

t= np.expand_dims(invert,axis =0)
p = loaded_model.predict(t,batch_size=1)

ind = np.argmax(p)
print(ind)

# Characters = 'क ख ग घ ङ च छ ज झ ञ ट ठ ड ढ ण त थ द ध न प फ ब भ म य र ल व श ष स ह क्ष त्र ज्ञ ० १ २ ३ ४ ५ ६ ७ ८ ९'
hindi_labels = ['ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'क', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'ख', 'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९']

path = 'DevanagariHandwrittenCharacterDataset'

labels = {'character_10_yna': 0, 'character_11_taamatar': 1, 'character_12_thaa': 2, 'character_13_daa': 3, 'character_14_dhaa': 4, 'character_15_adna': 5, 'character_16_tabala': 6, 'character_17_tha': 7, 'character_18_da': 8, 'character_19_dha': 9, 'character_1_ka': 10, 'character_20_na': 11, 'character_21_pa': 12, 'character_22_pha': 13, 'character_23_ba': 14, 'character_24_bha': 15, 'character_25_ma': 16, 'character_26_yaw': 17, 'character_27_ra': 18, 'character_28_la': 19, 'character_29_waw': 20, 'character_2_kha': 21, 'character_30_motosaw': 22, 'character_31_petchiryakha': 23, 'character_32_patalosaw': 24, 'character_33_ha': 25, 'character_34_chhya': 26, 'character_35_tra': 27, 'character_36_gya': 28, 'character_3_ga': 29, 'character_4_gha': 30, 'character_5_kna': 31, 'character_6_cha': 32, 'character_7_chha': 33, 'character_8_ja': 34, 'character_9_jha': 35, 'digit_0': 36, 'digit_1': 37, 'digit_2': 38, 'digit_3': 39, 'digit_4': 40, 'digit_5': 41, 'digit_6': 42, 'digit_7': 43, 'digit_8': 44, 'digit_9': 45}
Characters = 'क ख ग घ ङ च छ ज झ ञ ट ठ ड ढ ण त थ द ध न प फ ब भ म य र ल व श ष स ह क्ष त्र ज्ञ ० १ २ ३ ४ ५ ६ ७ ८ ९'
Characters = Characters.split(" ")
key_list = list(labels.keys())

import re
def atoi(text):
    return int(text) if text.isdigit() else text
def natural_keys(text):
    return [ atoi(c) for c in re.split('(\d+)',text) ]
ls = os.listdir(path+'/Train')
ls.sort(key = natural_keys)

Cha_Uni = {}
for j,i in enumerate(ls):
    Cha_Uni[i] = Characters[j]

yy = ind
a = key_list[int(yy)]
print(Cha_Uni[a])

key_list

Cha_Uni

Hindi_labels=[]
for x in key_list:
    Hindi_labels.append(Cha_Uni[x])
print(Hindi_labels)

